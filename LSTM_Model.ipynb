{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, BatchNormalization, Masking, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['op_setting1', 'op_setting2', 'op_setting3', 'sen_measurement1', 'sen_measurement5', 'sen_measurement6', 'sen_measurement9', 'sen_measurement10', 'sen_measurement14', 'sen_measurement16', 'sen_measurement18', 'sen_measurement19']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_FD001.csv\")\n",
    "temp_df = pd.read_csv(\"train_FD001_selected_features.csv\")\n",
    "drop_columns = [x for x in df if x not in temp_df.columns and x!='unit_number']\n",
    "print(drop_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       unit_number  time  sen_measurement2  sen_measurement3  \\\n0                1     1            641.82           1589.70   \n1                1     2            642.15           1591.82   \n2                1     3            642.35           1587.99   \n3                1     4            642.35           1582.79   \n4                1     5            642.37           1582.85   \n...            ...   ...               ...               ...   \n20626          100   196            643.49           1597.98   \n20627          100   197            643.54           1604.50   \n20628          100   198            643.42           1602.46   \n20629          100   199            643.23           1605.26   \n20630          100   200            643.85           1600.38   \n\n       sen_measurement4  sen_measurement7  sen_measurement8  \\\n0               1400.60            554.36           2388.06   \n1               1403.14            553.75           2388.04   \n2               1404.20            554.26           2388.08   \n3               1401.87            554.45           2388.11   \n4               1406.22            554.00           2388.06   \n...                 ...               ...               ...   \n20626           1428.63            551.43           2388.19   \n20627           1433.58            550.86           2388.23   \n20628           1428.18            550.94           2388.24   \n20629           1426.53            550.68           2388.25   \n20630           1432.14            550.79           2388.26   \n\n       sen_measurement11  sen_measurement12  sen_measurement13  \\\n0                  47.47             521.66            2388.02   \n1                  47.49             522.28            2388.07   \n2                  47.27             522.42            2388.03   \n3                  47.13             522.86            2388.08   \n4                  47.28             522.19            2388.04   \n...                  ...                ...                ...   \n20626              48.07             519.49            2388.26   \n20627              48.04             519.68            2388.22   \n20628              48.09             520.01            2388.24   \n20629              48.39             519.67            2388.23   \n20630              48.20             519.30            2388.26   \n\n       sen_measurement15  sen_measurement17  sen_measurement20  \\\n0                 8.4195                392              39.06   \n1                 8.4318                392              39.00   \n2                 8.4178                390              38.95   \n3                 8.3682                392              38.88   \n4                 8.4294                393              38.90   \n...                  ...                ...                ...   \n20626             8.4956                397              38.49   \n20627             8.5139                395              38.30   \n20628             8.5646                398              38.44   \n20629             8.5389                395              38.29   \n20630             8.5036                396              38.37   \n\n       sen_measurement21  RUL  \n0                23.4190  191  \n1                23.4236  190  \n2                23.3442  189  \n3                23.3739  188  \n4                23.4044  187  \n...                  ...  ...  \n20626            22.9735    4  \n20627            23.1594    3  \n20628            22.9333    2  \n20629            23.0640    1  \n20630            23.0522    0  \n\n[20631 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_number</th>\n      <th>time</th>\n      <th>sen_measurement2</th>\n      <th>sen_measurement3</th>\n      <th>sen_measurement4</th>\n      <th>sen_measurement7</th>\n      <th>sen_measurement8</th>\n      <th>sen_measurement11</th>\n      <th>sen_measurement12</th>\n      <th>sen_measurement13</th>\n      <th>sen_measurement15</th>\n      <th>sen_measurement17</th>\n      <th>sen_measurement20</th>\n      <th>sen_measurement21</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>641.82</td>\n      <td>1589.70</td>\n      <td>1400.60</td>\n      <td>554.36</td>\n      <td>2388.06</td>\n      <td>47.47</td>\n      <td>521.66</td>\n      <td>2388.02</td>\n      <td>8.4195</td>\n      <td>392</td>\n      <td>39.06</td>\n      <td>23.4190</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>553.75</td>\n      <td>2388.04</td>\n      <td>47.49</td>\n      <td>522.28</td>\n      <td>2388.07</td>\n      <td>8.4318</td>\n      <td>392</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>554.26</td>\n      <td>2388.08</td>\n      <td>47.27</td>\n      <td>522.42</td>\n      <td>2388.03</td>\n      <td>8.4178</td>\n      <td>390</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>554.45</td>\n      <td>2388.11</td>\n      <td>47.13</td>\n      <td>522.86</td>\n      <td>2388.08</td>\n      <td>8.3682</td>\n      <td>392</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>554.00</td>\n      <td>2388.06</td>\n      <td>47.28</td>\n      <td>522.19</td>\n      <td>2388.04</td>\n      <td>8.4294</td>\n      <td>393</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n      <td>187</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20626</th>\n      <td>100</td>\n      <td>196</td>\n      <td>643.49</td>\n      <td>1597.98</td>\n      <td>1428.63</td>\n      <td>551.43</td>\n      <td>2388.19</td>\n      <td>48.07</td>\n      <td>519.49</td>\n      <td>2388.26</td>\n      <td>8.4956</td>\n      <td>397</td>\n      <td>38.49</td>\n      <td>22.9735</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20627</th>\n      <td>100</td>\n      <td>197</td>\n      <td>643.54</td>\n      <td>1604.50</td>\n      <td>1433.58</td>\n      <td>550.86</td>\n      <td>2388.23</td>\n      <td>48.04</td>\n      <td>519.68</td>\n      <td>2388.22</td>\n      <td>8.5139</td>\n      <td>395</td>\n      <td>38.30</td>\n      <td>23.1594</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20628</th>\n      <td>100</td>\n      <td>198</td>\n      <td>643.42</td>\n      <td>1602.46</td>\n      <td>1428.18</td>\n      <td>550.94</td>\n      <td>2388.24</td>\n      <td>48.09</td>\n      <td>520.01</td>\n      <td>2388.24</td>\n      <td>8.5646</td>\n      <td>398</td>\n      <td>38.44</td>\n      <td>22.9333</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>20629</th>\n      <td>100</td>\n      <td>199</td>\n      <td>643.23</td>\n      <td>1605.26</td>\n      <td>1426.53</td>\n      <td>550.68</td>\n      <td>2388.25</td>\n      <td>48.39</td>\n      <td>519.67</td>\n      <td>2388.23</td>\n      <td>8.5389</td>\n      <td>395</td>\n      <td>38.29</td>\n      <td>23.0640</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20630</th>\n      <td>100</td>\n      <td>200</td>\n      <td>643.85</td>\n      <td>1600.38</td>\n      <td>1432.14</td>\n      <td>550.79</td>\n      <td>2388.26</td>\n      <td>48.20</td>\n      <td>519.30</td>\n      <td>2388.26</td>\n      <td>8.5036</td>\n      <td>396</td>\n      <td>38.37</td>\n      <td>23.0522</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20631 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(drop_columns, axis=1, inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def gen_train(id_df, seq_len, seq_cols):\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    lstm_array=[]\n",
    "\n",
    "    for start, stop in zip(range(0, num_elements-seq_len+1), range(seq_len, num_elements+1)):\n",
    "        lstm_array.append(data_array[start:stop, :])\n",
    "        return np.array(lstm_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def gen_target(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length-1:num_elements+1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_Columns = [column for column in df.columns if column!='RUL']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df[X_Columns] = min_max_scaler.fit_transform(df[X_Columns])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "       unit_number      time  sen_measurement2  sen_measurement3  \\\n0             -1.0 -1.000000         -0.632530         -0.186396   \n1             -1.0 -0.994460         -0.433735         -0.093961   \n2             -1.0 -0.988920         -0.313253         -0.260955   \n3             -1.0 -0.983380         -0.313253         -0.487683   \n4             -1.0 -0.977839         -0.301205         -0.485066   \n...            ...       ...               ...               ...   \n20626          1.0  0.080332          0.373494          0.174624   \n20627          1.0  0.085873          0.403614          0.458906   \n20628          1.0  0.091413          0.331325          0.369959   \n20629          1.0  0.096953          0.216867          0.492043   \n20630          1.0  0.102493          0.590361          0.279267   \n\n       sen_measurement4  sen_measurement7  sen_measurement8  \\\n0             -0.380486          0.452496         -0.515152   \n1             -0.294733          0.256039         -0.575758   \n2             -0.258947          0.420290         -0.454545   \n3             -0.337610          0.481481         -0.363636   \n4             -0.190749          0.336554         -0.515152   \n...                 ...               ...               ...   \n20626          0.565834         -0.491143         -0.121212   \n20627          0.732951         -0.674718          0.000000   \n20628          0.550641         -0.648953          0.030303   \n20629          0.494936         -0.732689          0.060606   \n20630          0.684335         -0.697262          0.090909   \n\n       sen_measurement11  sen_measurement12  sen_measurement13  \\\n0              -0.261905           0.266525      -5.882353e-01   \n1              -0.238095           0.530917      -4.411765e-01   \n2              -0.500000           0.590618      -5.588235e-01   \n3              -0.666667           0.778252      -4.117647e-01   \n4              -0.488095           0.492537      -5.294118e-01   \n...                  ...                ...                ...   \n20626           0.452381          -0.658849       1.176471e-01   \n20627           0.416667          -0.577825      -9.094947e-13   \n20628           0.476190          -0.437100       5.882353e-02   \n20629           0.833333          -0.582090       2.941176e-02   \n20630           0.607143          -0.739872       1.176471e-01   \n\n       sen_measurement15  sen_measurement17  sen_measurement20  \\\n0              -0.272028          -0.333333           0.426357   \n1              -0.177376          -0.333333           0.333333   \n2              -0.285110          -0.666667           0.255814   \n3              -0.666795          -0.333333           0.147287   \n4              -0.195845          -0.166667           0.178295   \n...                  ...                ...                ...   \n20626           0.313582           0.500000          -0.457364   \n20627           0.454406           0.166667          -0.751938   \n20628           0.844556           0.666667          -0.534884   \n20629           0.646787           0.166667          -0.767442   \n20630           0.375144           0.333333          -0.643411   \n\n       sen_measurement21  RUL  \n0               0.449323  191  \n1               0.462027  190  \n2               0.242751  189  \n3               0.324772  188  \n4               0.409003  187  \n...                  ...  ...  \n20626          -0.781000    4  \n20627          -0.267606    3  \n20628          -0.892019    2  \n20629          -0.531069    1  \n20630          -0.563656    0  \n\n[20631 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_number</th>\n      <th>time</th>\n      <th>sen_measurement2</th>\n      <th>sen_measurement3</th>\n      <th>sen_measurement4</th>\n      <th>sen_measurement7</th>\n      <th>sen_measurement8</th>\n      <th>sen_measurement11</th>\n      <th>sen_measurement12</th>\n      <th>sen_measurement13</th>\n      <th>sen_measurement15</th>\n      <th>sen_measurement17</th>\n      <th>sen_measurement20</th>\n      <th>sen_measurement21</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-0.632530</td>\n      <td>-0.186396</td>\n      <td>-0.380486</td>\n      <td>0.452496</td>\n      <td>-0.515152</td>\n      <td>-0.261905</td>\n      <td>0.266525</td>\n      <td>-5.882353e-01</td>\n      <td>-0.272028</td>\n      <td>-0.333333</td>\n      <td>0.426357</td>\n      <td>0.449323</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.0</td>\n      <td>-0.994460</td>\n      <td>-0.433735</td>\n      <td>-0.093961</td>\n      <td>-0.294733</td>\n      <td>0.256039</td>\n      <td>-0.575758</td>\n      <td>-0.238095</td>\n      <td>0.530917</td>\n      <td>-4.411765e-01</td>\n      <td>-0.177376</td>\n      <td>-0.333333</td>\n      <td>0.333333</td>\n      <td>0.462027</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.0</td>\n      <td>-0.988920</td>\n      <td>-0.313253</td>\n      <td>-0.260955</td>\n      <td>-0.258947</td>\n      <td>0.420290</td>\n      <td>-0.454545</td>\n      <td>-0.500000</td>\n      <td>0.590618</td>\n      <td>-5.588235e-01</td>\n      <td>-0.285110</td>\n      <td>-0.666667</td>\n      <td>0.255814</td>\n      <td>0.242751</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.0</td>\n      <td>-0.983380</td>\n      <td>-0.313253</td>\n      <td>-0.487683</td>\n      <td>-0.337610</td>\n      <td>0.481481</td>\n      <td>-0.363636</td>\n      <td>-0.666667</td>\n      <td>0.778252</td>\n      <td>-4.117647e-01</td>\n      <td>-0.666795</td>\n      <td>-0.333333</td>\n      <td>0.147287</td>\n      <td>0.324772</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.0</td>\n      <td>-0.977839</td>\n      <td>-0.301205</td>\n      <td>-0.485066</td>\n      <td>-0.190749</td>\n      <td>0.336554</td>\n      <td>-0.515152</td>\n      <td>-0.488095</td>\n      <td>0.492537</td>\n      <td>-5.294118e-01</td>\n      <td>-0.195845</td>\n      <td>-0.166667</td>\n      <td>0.178295</td>\n      <td>0.409003</td>\n      <td>187</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20626</th>\n      <td>1.0</td>\n      <td>0.080332</td>\n      <td>0.373494</td>\n      <td>0.174624</td>\n      <td>0.565834</td>\n      <td>-0.491143</td>\n      <td>-0.121212</td>\n      <td>0.452381</td>\n      <td>-0.658849</td>\n      <td>1.176471e-01</td>\n      <td>0.313582</td>\n      <td>0.500000</td>\n      <td>-0.457364</td>\n      <td>-0.781000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20627</th>\n      <td>1.0</td>\n      <td>0.085873</td>\n      <td>0.403614</td>\n      <td>0.458906</td>\n      <td>0.732951</td>\n      <td>-0.674718</td>\n      <td>0.000000</td>\n      <td>0.416667</td>\n      <td>-0.577825</td>\n      <td>-9.094947e-13</td>\n      <td>0.454406</td>\n      <td>0.166667</td>\n      <td>-0.751938</td>\n      <td>-0.267606</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20628</th>\n      <td>1.0</td>\n      <td>0.091413</td>\n      <td>0.331325</td>\n      <td>0.369959</td>\n      <td>0.550641</td>\n      <td>-0.648953</td>\n      <td>0.030303</td>\n      <td>0.476190</td>\n      <td>-0.437100</td>\n      <td>5.882353e-02</td>\n      <td>0.844556</td>\n      <td>0.666667</td>\n      <td>-0.534884</td>\n      <td>-0.892019</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>20629</th>\n      <td>1.0</td>\n      <td>0.096953</td>\n      <td>0.216867</td>\n      <td>0.492043</td>\n      <td>0.494936</td>\n      <td>-0.732689</td>\n      <td>0.060606</td>\n      <td>0.833333</td>\n      <td>-0.582090</td>\n      <td>2.941176e-02</td>\n      <td>0.646787</td>\n      <td>0.166667</td>\n      <td>-0.767442</td>\n      <td>-0.531069</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20630</th>\n      <td>1.0</td>\n      <td>0.102493</td>\n      <td>0.590361</td>\n      <td>0.279267</td>\n      <td>0.684335</td>\n      <td>-0.697262</td>\n      <td>0.090909</td>\n      <td>0.607143</td>\n      <td>-0.739872</td>\n      <td>1.176471e-01</td>\n      <td>0.375144</td>\n      <td>0.333333</td>\n      <td>-0.643411</td>\n      <td>-0.563656</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20631 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20631, 50, 14)\n",
      "y_train shape: (15731,)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 50\n",
    "X_train = np.concatenate(list(list(gen_train(df[df['unit_number']==unit], sequence_length, X_Columns)) for unit in df[\"unit_number\"]))\n",
    "print(\"X_train shape:\",X_train.shape)\n",
    "pass\n",
    "y_train = np.concatenate(list(list(gen_target(df[df[\"unit_number\"]==Unit], sequence_length, \"RUL\")) for Unit in df[\"unit_number\"].unique()))\n",
    "print(\"y_train shape:\",y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeTa5\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "nb_features = X_train.shape[2]\n",
    "nb_out = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 256,\n",
    "               return_sequences=True,\n",
    "               input_shape=(sequence_length, nb_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128,\n",
    "               return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(loss='mse',optimizer='rmsprop', metrics=['mse'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_3\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_6 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │       \u001B[38;5;34m277,504\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │         \u001B[38;5;34m1,024\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_7 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m197,120\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_2 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">277,504</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m475,777\u001B[0m (1.81 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">475,777</span> (1.81 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m475,265\u001B[0m (1.81 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">475,265</span> (1.81 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m512\u001B[0m (2.00 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs= 10, batch_size=32, validation_split=0.1, verbose=1, callbacks=[EarlyStopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}